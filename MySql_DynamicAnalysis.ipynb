{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Detail above the folder created and csv file**\\\n",
        "**In the mysql_dynamic_analysis folder**\n",
        "1. docker-compose.yaml --> this file is to run the docker\n",
        "2. simulate_activity.py --> python script for normal and attack activity\n",
        "3. mysql_configs --> is has the vulnerable and non vulnerable configuraton with vulvariant and nonvulvariant\n",
        "4. mysql_logs --> it contains the logs from the python script running with each folder with vulvariant and vulvariant and inside each folder we have 2 subfolder as error.log and general.log\n",
        "5. Rest are the csv dataset created from the logs folder, please refer to code for further details.\n"
      ],
      "metadata": {
        "id": "gv4ICIER2Ni9"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HIwoqFplPWbP",
        "outputId": "1247f5e6-3eac-4bcd-95dc-ad3c078a101c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset created with 7367904 entries and saved to /content/drive/MyDrive/Dynamic_Analysis/mysql_dynamic_analysis/dynamic_analysis_dataset.csv\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import re\n",
        "import pandas as pd\n",
        "from datetime import datetime\n",
        "\n",
        "cwe_mapping = {\n",
        "    r\"DROP DATABASE\": \"CWE-287\",\n",
        "    r\"GRANT ALL PRIVILEGES\": \"CWE-264\",\n",
        "    r\"SELECT .*SLEEP\": \"CWE-400\",\n",
        "    r\"non_existing_table' OR '1'='1\": \"CWE-89\"\n",
        "}\n",
        "\n",
        "def extract_timestamp(line):\n",
        "    pattern = r'^(\\d{4}-\\d{2}-\\d{2} \\d{2}:\\d{2}:\\d{2})'\n",
        "    match = re.match(pattern, line)\n",
        "    if match:\n",
        "        return match.group(1)\n",
        "    return \"\"\n",
        "\n",
        "def determine_log_type(file_name):\n",
        "    lower_name = file_name.lower()\n",
        "    if \"error\" in lower_name:\n",
        "        return \"error\"\n",
        "    elif \"general\" in lower_name:\n",
        "        return \"general\"\n",
        "    else:\n",
        "        return \"unknown\"\n",
        "\n",
        "def detect_cwe(log_message):\n",
        "    for pattern, cwe in cwe_mapping.items():\n",
        "        if re.search(pattern, log_message, re.IGNORECASE):\n",
        "            return cwe\n",
        "    return \"\"\n",
        "\n",
        "def parse_log_file(file_path, source_folder):\n",
        "    entries = []\n",
        "    log_type = determine_log_type(os.path.basename(file_path))\n",
        "    label = 1 if \"vulvariant\" in source_folder.lower() else 0\n",
        "\n",
        "    try:\n",
        "        with open(file_path, 'r', encoding='utf-8', errors='ignore') as f:\n",
        "            for line in f:\n",
        "                line = line.strip()\n",
        "                if not line:\n",
        "                    continue\n",
        "                timestamp = extract_timestamp(line)\n",
        "                cwe = detect_cwe(line)\n",
        "                entries.append({\n",
        "                    \"timestamp\": timestamp,\n",
        "                    \"source\": source_folder,\n",
        "                    \"log_type\": log_type,\n",
        "                    \"log_message\": line,\n",
        "                    \"cwe\": cwe,\n",
        "                    \"label\": label\n",
        "                })\n",
        "    except Exception as e:\n",
        "        print(f\"Error reading {file_path}: {e}\")\n",
        "    return entries\n",
        "\n",
        "def build_dataset(logs_root):\n",
        "    all_entries = []\n",
        "    for variant in os.listdir(logs_root):\n",
        "        variant_path = os.path.join(logs_root, variant)\n",
        "        if os.path.isdir(variant_path):\n",
        "            for file in os.listdir(variant_path):\n",
        "                file_path = os.path.join(variant_path, file)\n",
        "                entries = parse_log_file(file_path, variant)\n",
        "                all_entries.extend(entries)\n",
        "    return pd.DataFrame(all_entries)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # Set the logs directory path\n",
        "    logs_directory = \"/content/drive/MyDrive/Dynamic_Analysis/mysql_dynamic_analysis/mysql_logs\"\n",
        "\n",
        "    # Build the dataset from the logs\n",
        "    df_dataset = build_dataset(logs_directory)\n",
        "\n",
        "    # Save the DataFrame to CSV\n",
        "    output_csv = \"/content/drive/MyDrive/Dynamic_Analysis/mysql_dynamic_analysis/dynamic_analysis_dataset.csv\"\n",
        "    df_dataset.to_csv(output_csv, index=False)\n",
        "\n",
        "    print(f\"Dataset created with {len(df_dataset)} entries and saved to {output_csv}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load your CSV file\n",
        "df = pd.read_csv(\"/content/drive/MyDrive/Dynamic_Analysis/mysql_dynamic_analysis/dynamic_analysis_dataset.csv\")\n",
        "\n",
        "# Print the number of rows and columns\n",
        "print(\"Total Rows:\", df.shape[0])\n",
        "print(\"Total Columns:\", df.shape[1])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c9S7vvETSoTR",
        "outputId": "1eea23de-5624-4dfd-8ac8-d78b7af2834e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-4846741b0b56>:4: DtypeWarning: Columns (4) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  df = pd.read_csv(\"/content/drive/MyDrive/Dynamic_Analysis/mysql_dynamic_analysis/dynamic_analysis_dataset.csv\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total Rows: 7367904\n",
            "Total Columns: 6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load your CSV file\n",
        "df = pd.read_csv(\"/content/drive/MyDrive/Dynamic_Analysis/mysql_dynamic_analysis/dynamic_analysis_dataset.csv\")\n",
        "\n",
        "# Display the first 5 rows\n",
        "print(df.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_jrtor_xSwP5",
        "outputId": "dc21caab-f195-4b81-d072-35b1f43b4a96"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-4-052c100e6f43>:4: DtypeWarning: Columns (4) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  df = pd.read_csv(\"/content/drive/MyDrive/Dynamic_Analysis/mysql_dynamic_analysis/dynamic_analysis_dataset.csv\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   timestamp        source log_type  \\\n",
            "0        NaN  vulvariant47    error   \n",
            "1        NaN  vulvariant47    error   \n",
            "2        NaN  vulvariant47    error   \n",
            "3        NaN  vulvariant47    error   \n",
            "4        NaN  vulvariant47    error   \n",
            "\n",
            "                                         log_message  cwe  label  \n",
            "0  2025-03-07T18:59:11.694005Z 0 [Warning] TIMEST...  NaN      1  \n",
            "1  2025-03-07T18:59:21.067981Z 0 [Warning] InnoDB...  NaN      1  \n",
            "2  2025-03-07T18:59:24.289415Z 0 [Warning] InnoDB...  NaN      1  \n",
            "3  2025-03-07T18:59:24.904353Z 0 [Warning] No exi...  NaN      1  \n",
            "4  2025-03-07T18:59:24.925120Z 0 [Warning] Gtid t...  NaN      1  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**In the above dynamic_analysis_dataset time stamp was not coming**"
      ],
      "metadata": {
        "id": "IdFJE1Ltyw5k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import re\n",
        "import pandas as pd\n",
        "from datetime import datetime\n",
        "\n",
        "# Mapping for CWE detection\n",
        "cwe_mapping = {\n",
        "    r\"DROP DATABASE\": \"CWE-287\",\n",
        "    r\"GRANT ALL PRIVILEGES\": \"CWE-264\",\n",
        "    r\"SELECT .*SLEEP\": \"CWE-400\",\n",
        "    r\"non_existing_table' OR '1'='1\": \"CWE-89\"\n",
        "}\n",
        "\n",
        "# Functions\n",
        "def extract_timestamp(line):\n",
        "    pattern = r'^(\\d{4}-\\d{2}-\\d{2}T\\d{2}:\\d{2}:\\d{2}\\.\\d+Z)'\n",
        "    match = re.match(pattern, line)\n",
        "    if match:\n",
        "        return match.group(1)\n",
        "    return \"\"\n",
        "\n",
        "def determine_log_type(file_name):\n",
        "    lower_name = file_name.lower()\n",
        "    if \"error\" in lower_name:\n",
        "        return \"error\"\n",
        "    elif \"general\" in lower_name:\n",
        "        return \"general\"\n",
        "    else:\n",
        "        return \"unknown\"\n",
        "\n",
        "def detect_cwe(log_message):\n",
        "    for pattern, cwe in cwe_mapping.items():\n",
        "        if re.search(pattern, log_message, re.IGNORECASE):\n",
        "            return cwe\n",
        "    return \"\"\n",
        "\n",
        "def parse_log_file(file_path, source_folder):\n",
        "    entries = []\n",
        "    log_type = determine_log_type(os.path.basename(file_path))\n",
        "    label = 1 if \"vulvariant\" in source_folder.lower() else 0\n",
        "\n",
        "    try:\n",
        "        with open(file_path, 'r', encoding='utf-8', errors='ignore') as f:\n",
        "            for line in f:\n",
        "                line = line.strip()\n",
        "                if not line:\n",
        "                    continue\n",
        "                timestamp = extract_timestamp(line)\n",
        "                cwe = detect_cwe(line)\n",
        "                entries.append({\n",
        "                    \"timestamp\": timestamp,\n",
        "                    \"source\": source_folder,\n",
        "                    \"log_type\": log_type,\n",
        "                    \"log_message\": line,\n",
        "                    \"cwe\": cwe,\n",
        "                    \"label\": label\n",
        "                })\n",
        "    except Exception as e:\n",
        "        print(f\"Error reading {file_path}: {e}\")\n",
        "    return entries\n",
        "\n",
        "def build_dataset(logs_root):\n",
        "    all_entries = []\n",
        "    for variant in os.listdir(logs_root):\n",
        "        variant_path = os.path.join(logs_root, variant)\n",
        "        if os.path.isdir(variant_path):\n",
        "            for file in os.listdir(variant_path):\n",
        "                file_path = os.path.join(variant_path, file)\n",
        "                entries = parse_log_file(file_path, variant)\n",
        "                all_entries.extend(entries)\n",
        "    return pd.DataFrame(all_entries)\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # Path\n",
        "    logs_directory = \"/content/drive/MyDrive/Dynamic_Analysis/mysql_dynamic_analysis/mysql_logs\"\n",
        "\n",
        "    # Build the dataset\n",
        "    df_dataset = build_dataset(logs_directory)\n",
        "\n",
        "    # Display info\n",
        "    print(\"Total Rows:\", df_dataset.shape[0])\n",
        "    print(\"Total Columns:\", df_dataset.shape[1])\n",
        "    print(\"First 5 Rows:\")\n",
        "    print(df_dataset.head())\n",
        "\n",
        "    # Save the DataFrame to a CSV file\n",
        "    output_csv = \"/content/drive/MyDrive/Dynamic_Analysis/mysql_dynamic_analysis/dynamic_analysis.csv\"\n",
        "    df_dataset.to_csv(output_csv, index=False)\n",
        "    print(f\"Dataset saved to {output_csv}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i96C9b5hVR6c",
        "outputId": "d06da4d6-3a7c-4a9d-ad0c-724eca6d86b9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total Rows: 7367904\n",
            "Total Columns: 6\n",
            "First 5 Rows:\n",
            "                     timestamp        source log_type  \\\n",
            "0  2025-03-07T18:59:11.694005Z  vulvariant47    error   \n",
            "1  2025-03-07T18:59:21.067981Z  vulvariant47    error   \n",
            "2  2025-03-07T18:59:24.289415Z  vulvariant47    error   \n",
            "3  2025-03-07T18:59:24.904353Z  vulvariant47    error   \n",
            "4  2025-03-07T18:59:24.925120Z  vulvariant47    error   \n",
            "\n",
            "                                         log_message cwe  label  \n",
            "0  2025-03-07T18:59:11.694005Z 0 [Warning] TIMEST...          1  \n",
            "1  2025-03-07T18:59:21.067981Z 0 [Warning] InnoDB...          1  \n",
            "2  2025-03-07T18:59:24.289415Z 0 [Warning] InnoDB...          1  \n",
            "3  2025-03-07T18:59:24.904353Z 0 [Warning] No exi...          1  \n",
            "4  2025-03-07T18:59:24.925120Z 0 [Warning] Gtid t...          1  \n",
            "Dataset saved to /content/drive/MyDrive/Dynamic_Analysis/mysql_dynamic_analysis/dynamic_analysis.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**In the above dynamic_analysis cwe mapping was not proper**"
      ],
      "metadata": {
        "id": "p8J4OyZyy9z7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import re\n",
        "import pandas as pd\n",
        "from datetime import datetime\n",
        "\n",
        "# Mapping for CWE detection\n",
        "cwe_mapping = {\n",
        "    r\"DROP DATABASE\": \"CWE-287\",\n",
        "    r\"GRANT ALL PRIVILEGES\": \"CWE-264\",\n",
        "    r\"SELECT .*SLEEP\": \"CWE-400\",\n",
        "    r\"non_existing_table' OR '1'='1\": \"CWE-89\"\n",
        "}\n",
        "\n",
        "def extract_timestamp(line):\n",
        "    pattern = r'^(\\d{4}-\\d{2}-\\d{2}T\\d{2}:\\d{2}:\\d{2}\\.\\d+Z)'\n",
        "    match = re.match(pattern, line)\n",
        "    if match:\n",
        "        return match.group(1)\n",
        "    return \"\"\n",
        "\n",
        "def determine_log_type(file_name):\n",
        "    lower_name = file_name.lower()\n",
        "    if \"error\" in lower_name:\n",
        "        return \"error\"\n",
        "    elif \"general\" in lower_name:\n",
        "        return \"general\"\n",
        "    else:\n",
        "        return \"unknown\"\n",
        "\n",
        "def detect_cwe(log_message):\n",
        "    for pattern, cwe in cwe_mapping.items():\n",
        "        if re.search(pattern, log_message, re.IGNORECASE):\n",
        "            return cwe\n",
        "    return \"\"\n",
        "\n",
        "def parse_log_file(file_path, source_folder):\n",
        "    entries = []\n",
        "    log_type = determine_log_type(os.path.basename(file_path))\n",
        "    label = 1 if \"vulvariant\" in source_folder.lower() else 0\n",
        "\n",
        "    try:\n",
        "        with open(file_path, 'r', encoding='utf-8', errors='ignore') as f:\n",
        "            for line in f:\n",
        "                line = line.strip()\n",
        "                if not line:\n",
        "                    continue\n",
        "                timestamp = extract_timestamp(line)\n",
        "                if timestamp:\n",
        "                    message = line[len(timestamp):].strip()\n",
        "                else:\n",
        "                    message = line\n",
        "                cwe = detect_cwe(message)\n",
        "                entries.append({\n",
        "                    \"timestamp\": timestamp,\n",
        "                    \"source\": source_folder,\n",
        "                    \"log_type\": log_type,\n",
        "                    \"log_message\": message,\n",
        "                    \"cwe\": cwe,\n",
        "                    \"label\": label\n",
        "                })\n",
        "    except Exception as e:\n",
        "        print(f\"Error reading {file_path}: {e}\")\n",
        "    return entries\n",
        "\n",
        "def build_dataset(logs_root):\n",
        "    all_entries = []\n",
        "    for variant in os.listdir(logs_root):\n",
        "        variant_path = os.path.join(logs_root, variant)\n",
        "        if os.path.isdir(variant_path):\n",
        "            for file in os.listdir(variant_path):\n",
        "                file_path = os.path.join(variant_path, file)\n",
        "                entries = parse_log_file(file_path, variant)\n",
        "                all_entries.extend(entries)\n",
        "    return pd.DataFrame(all_entries)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # Path to the logs directory\n",
        "    logs_directory = \"/content/drive/MyDrive/Dynamic_Analysis/mysql_dynamic_analysis/mysql_logs\"\n",
        "\n",
        "    # Build the dataset\n",
        "    df_dataset = build_dataset(logs_directory)\n",
        "\n",
        "    # Display the first 5 rows for verification\n",
        "    print(\"First 5 rows of dataset:\")\n",
        "    print(df_dataset.head())\n",
        "\n",
        "    # Save the dataset as CSV\n",
        "    output_csv = \"/content/drive/MyDrive/Dynamic_Analysis/mysql_dynamic_analysis/dynamic_analysis_dataset1.csv\"\n",
        "    df_dataset.to_csv(output_csv, index=False)\n",
        "    print(f\"Dataset created with {len(df_dataset)} entries and saved to {output_csv}\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dAy0k9g1VdCf",
        "outputId": "ab77142d-2c4e-429a-c9b6-8eac5fc617ea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "First 5 rows of dataset:\n",
            "                     timestamp        source log_type  \\\n",
            "0  2025-03-07T18:59:11.694005Z  vulvariant47    error   \n",
            "1  2025-03-07T18:59:21.067981Z  vulvariant47    error   \n",
            "2  2025-03-07T18:59:24.289415Z  vulvariant47    error   \n",
            "3  2025-03-07T18:59:24.904353Z  vulvariant47    error   \n",
            "4  2025-03-07T18:59:24.925120Z  vulvariant47    error   \n",
            "\n",
            "                                         log_message cwe  label  \n",
            "0  0 [Warning] TIMESTAMP with implicit DEFAULT va...          1  \n",
            "1  0 [Warning] InnoDB: New log files created, LSN...          1  \n",
            "2  0 [Warning] InnoDB: Creating foreign key const...          1  \n",
            "3  0 [Warning] No existing UUID has been found, s...          1  \n",
            "4  0 [Warning] Gtid table is not ready to be used...          1  \n",
            "Dataset created with 7367904 entries and saved to /content/drive/MyDrive/Dynamic_Analysis/mysql_dynamic_analysis/dynamic_analysis_dataset1.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the CSV file\n",
        "df = pd.read_csv(\"/content/drive/MyDrive/Dynamic_Analysis/mysql_dynamic_analysis/dynamic_analysis_dataset1.csv\")\n",
        "\n",
        "# Display 5 random rows\n",
        "print(df.sample(5))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_2G-azPyX-Sx",
        "outputId": "0ec55173-57ad-421d-ddb4-785763efd927"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-7-8a7852894702>:4: DtypeWarning: Columns (4) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  df = pd.read_csv(\"/content/drive/MyDrive/Dynamic_Analysis/mysql_dynamic_analysis/dynamic_analysis_dataset1.csv\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                           timestamp           source log_type  \\\n",
            "2775740                          NaN     vulvariant27  general   \n",
            "2482417                          NaN     vulvariant28  general   \n",
            "2405964  2025-03-07T18:32:23.283907Z     vulvariant28  general   \n",
            "575509                           NaN     vulvariant48  general   \n",
            "6162402                          NaN  nonvulvariant28  general   \n",
            "\n",
            "                                               log_message  cwe  label  \n",
            "2775740                    ,(@time_zone_id, -464220000, 0)  NaN      1  \n",
            "2482417                     ,(@time_zone_id, 688554000, 5)  NaN      1  \n",
            "2405964  1 Query\\tINSERT INTO help_keyword (help_keywor...  NaN      1  \n",
            "575509                      ,(@time_zone_id, 104925600, 3)  NaN      1  \n",
            "6162402                    ,(@time_zone_id, 1869669000, 1)  NaN      1  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the CSV file\n",
        "df = pd.read_csv(\"/content/drive/MyDrive/Dynamic_Analysis/mysql_dynamic_analysis/dynamic_analysis_dataset1.csv\")\n",
        "\n",
        "# Display 5 random rows\n",
        "print(df.sample(5))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NJ9hu7eEYVcV",
        "outputId": "c00e4fa9-e5bd-44b4-ca05-0a9a194ef7ad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-8-8a7852894702>:4: DtypeWarning: Columns (4) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  df = pd.read_csv(\"/content/drive/MyDrive/Dynamic_Analysis/mysql_dynamic_analysis/dynamic_analysis_dataset1.csv\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                           timestamp           source log_type  \\\n",
            "1511734                          NaN     vulvariant36  general   \n",
            "1672498                          NaN     vulvariant33  general   \n",
            "2913596                          NaN     vulvariant26  general   \n",
            "6740082  2025-03-07T17:51:46.335018Z   nonvulvariant1  general   \n",
            "6886672                          NaN  nonvulvariant15  general   \n",
            "\n",
            "                                               log_message  cwe  label  \n",
            "1511734                     ,(@time_zone_id, 701798400, 2)  NaN      1  \n",
            "1672498                    ,(@time_zone_id, -560203200, 2)  NaN      1  \n",
            "2913596                     ,(@time_zone_id, 386699400, 1)  NaN      1  \n",
            "6740082  3 Query\\tINSERT INTO time_zone_transition_type...  NaN      1  \n",
            "6886672                    ,(@time_zone_id, 1004230800, 8)  NaN      1  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import re\n",
        "import pandas as pd\n",
        "from datetime import datetime\n",
        "\n",
        "# mapping for CWE detection\n",
        "cwe_mapping = {\n",
        "    r\"DROP DATABASE\": \"CWE-287\",\n",
        "    r\"GRANT ALL PRIVILEGES\": \"CWE-264\",\n",
        "    r\"SELECT .*SLEEP\": \"CWE-400\",\n",
        "    r\"non_existing_table' OR '1'='1\": \"CWE-89\",\n",
        "    r\"TIMESTAMP with implicit DEFAULT value is deprecated\": \"CWE-489\",\n",
        "    r\"A deprecated TLS version TLSv1\": \"CWE-326\",\n",
        "    r\"A deprecated TLS version TLSv1\\.1\": \"CWE-326\",\n",
        "    r\"CA certificate .* is self signed\": \"CWE-295\",\n",
        "    r\"created with an empty password\": \"CWE-798\",\n",
        "    r\"'NO_AUTO_CREATE_USER' sql mode was not set\": \"CWE-16\"\n",
        "}\n",
        "\n",
        "def extract_timestamp(line):\n",
        "    pattern = r'^(\\d{4}-\\d{2}-\\d{2}T\\d{2}:\\d{2}:\\d{2}\\.\\d+Z)'\n",
        "    match = re.match(pattern, line)\n",
        "    if match:\n",
        "        return match.group(1)\n",
        "    return \"\"\n",
        "\n",
        "def determine_log_type(file_name):\n",
        "    lower_name = file_name.lower()\n",
        "    if \"error\" in lower_name:\n",
        "        return \"error\"\n",
        "    elif \"general\" in lower_name:\n",
        "        return \"general\"\n",
        "    else:\n",
        "        return \"unknown\"\n",
        "\n",
        "def detect_cwe(log_message):\n",
        "    for pattern, cwe in cwe_mapping.items():\n",
        "        if re.search(pattern, log_message, re.IGNORECASE):\n",
        "            return cwe\n",
        "    return \"\"\n",
        "\n",
        "def parse_log_file(file_path, source_folder):\n",
        "    entries = []\n",
        "    log_type = determine_log_type(os.path.basename(file_path))\n",
        "    container_type = \"vulnerable\" if \"vulvariant\" in source_folder.lower() else \"nonvulnerable\"\n",
        "\n",
        "    current_entry = None\n",
        "    try:\n",
        "        with open(file_path, 'r', encoding='utf-8', errors='ignore') as f:\n",
        "            for line in f:\n",
        "                line = line.rstrip(\"\\n\")\n",
        "                if not line:\n",
        "                    continue\n",
        "                ts = extract_timestamp(line)\n",
        "                if ts:\n",
        "                    if current_entry is not None:\n",
        "                        entries.append(current_entry)\n",
        "                    remainder = line[len(ts):].strip()\n",
        "                    current_entry = {\n",
        "                        \"timestamp\": ts,\n",
        "                        \"source\": source_folder,\n",
        "                        \"container_type\": container_type,\n",
        "                        \"log_type\": log_type,\n",
        "                        \"log_message\": remainder,\n",
        "                        \"cwe\": \"\",\n",
        "                        \"label\": None\n",
        "                    }\n",
        "                else:\n",
        "                    if current_entry is not None:\n",
        "                        current_entry[\"log_message\"] += \" \" + line.strip()\n",
        "                    else:\n",
        "                        continue\n",
        "            if current_entry is not None:\n",
        "                entries.append(current_entry)\n",
        "    except Exception as e:\n",
        "        print(f\"Error reading {file_path}: {e}\")\n",
        ".\n",
        "    for entry in entries:\n",
        "        cwe_detected = detect_cwe(entry[\"log_message\"])\n",
        "        entry[\"cwe\"] = cwe_detected if cwe_detected else \"0\"\n",
        "        entry[\"label\"] = 1 if cwe_detected else 0\n",
        "\n",
        "    return entries\n",
        "\n",
        "def build_dataset(logs_root):\n",
        "    all_entries = []\n",
        "    for variant in os.listdir(logs_root):\n",
        "        variant_path = os.path.join(logs_root, variant)\n",
        "        if os.path.isdir(variant_path):\n",
        "            for file in os.listdir(variant_path):\n",
        "                file_path = os.path.join(variant_path, file)\n",
        "                entries = parse_log_file(file_path, variant)\n",
        "                all_entries.extend(entries)\n",
        "    return pd.DataFrame(all_entries)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # Set the logs directory\n",
        "    logs_directory = \"/content/drive/MyDrive/Dynamic_Analysis/mysql_dynamic_analysis/mysql_logs\"\n",
        "\n",
        "    # Build the dataset\n",
        "    df_dataset = build_dataset(logs_directory)\n",
        "\n",
        "    # Print 5 random rows for verification\n",
        "    print(\"Random 5 rows from dataset:\")\n",
        "    print(df_dataset.sample(5))\n",
        "\n",
        "    # Save the DataFrame to a CSV file\n",
        "    output_csv = \"/content/drive/MyDrive/Dynamic_Analysis/mysql_dynamic_analysis/dynamic_analysis_dataset2.csv\"\n",
        "    df_dataset.to_csv(output_csv, index=False)\n",
        "\n",
        "    print(f\"Dataset created with {len(df_dataset)} entries and saved to {output_csv}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KrHzcCgU-fxw",
        "outputId": "68ac21a7-664e-48d7-d80a-302183045d21"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random 5 rows from dataset:\n",
            "                          timestamp           source container_type log_type  \\\n",
            "539414  2025-03-07T18:16:54.791704Z   nonvulvariant8     vulnerable  general   \n",
            "271835  2025-03-07T18:33:51.742221Z     vulvariant24     vulnerable  general   \n",
            "765455  2025-03-07T18:32:21.795097Z  nonvulvariant26     vulnerable  general   \n",
            "214481  2025-03-07T18:39:28.294765Z     vulvariant32     vulnerable  general   \n",
            "705729  2025-03-07T18:34:03.220894Z  nonvulvariant22     vulnerable  general   \n",
            "\n",
            "                                              log_message cwe  label  \n",
            "539414       3 Query\\tSET @time_zone_id= LAST_INSERT_ID()   0      0  \n",
            "271835  3 Query\\tINSERT INTO time_zone_transition_type...   0      0  \n",
            "765455  1 Query\\tINSERT INTO help_keyword (help_keywor...   0      0  \n",
            "214481                        1 Query\\tDROP PREPARE stmt;   0      0  \n",
            "705729  3 Query\\tINSERT INTO time_zone_transition_type...   0      0  \n",
            "Dataset created with 911888 entries and saved to /content/drive/MyDrive/Dynamic_Analysis/mysql_dynamic_analysis/dynamic_analysis_dataset2.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the CSV file (adjust the path as needed)\n",
        "df = pd.read_csv(\"/content/drive/MyDrive/Dynamic_Analysis/mysql_dynamic_analysis/dynamic_analysis_dataset2.csv\")\n",
        "\n",
        "# Display 5 random rows\n",
        "print(df.sample(5))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u74i1ki5s16e",
        "outputId": "299897d0-96b9-47d1-fec0-7a5f4bcac12f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                          timestamp           source container_type log_type  \\\n",
            "186233  2025-03-07T18:55:16.153106Z     vulvariant35     vulnerable  general   \n",
            "457162  2025-03-07T18:28:11.804081Z     vulvariant17     vulnerable  general   \n",
            "439724  2025-03-07T18:32:24.282778Z     vulvariant19     vulnerable  general   \n",
            "562551  2025-03-07T17:59:45.680309Z   nonvulvariant9     vulnerable  general   \n",
            "902834  2025-03-07T18:33:54.917728Z  nonvulvariant20     vulnerable  general   \n",
            "\n",
            "                                              log_message cwe  label  \n",
            "186233                             1 Query\\tEXECUTE stmt;   0      0  \n",
            "457162  3 Query\\tINSERT INTO time_zone_transition (Tim...   0      0  \n",
            "439724  1 Query\\tINSERT INTO help_relation (help_topic...   0      0  \n",
            "562551  1 Prepare\\tCREATE TABLE performance_schema.thr...   0      0  \n",
            "902834  3 Query\\tINSERT INTO time_zone_transition (Tim...   0      0  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the CSV file\n",
        "df = pd.read_csv(\"/content/drive/MyDrive/Dynamic_Analysis/mysql_dynamic_analysis/dynamic_analysis_dataset2.csv\")\n",
        "\n",
        "# Display 5 random rows\n",
        "print(df.sample(5))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TjPpIF-xt2y-",
        "outputId": "0a7855db-7b26-45c3-de82-bc7c3918c8a9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                          timestamp           source container_type log_type  \\\n",
            "254388  2025-03-07T18:33:30.377802Z     vulvariant23     vulnerable  general   \n",
            "430003  2025-03-07T18:27:27.729342Z     vulvariant15     vulnerable  general   \n",
            "190553  2025-03-07T18:55:58.982183Z     vulvariant35     vulnerable  general   \n",
            "594782  2025-03-07T18:59:33.983834Z  nonvulvariant43     vulnerable  general   \n",
            "640547  2025-03-07T18:59:40.376576Z  nonvulvariant47     vulnerable  general   \n",
            "\n",
            "                                              log_message cwe  label  \n",
            "254388  3 Query\\tINSERT INTO time_zone_name (Name, Tim...   0      0  \n",
            "430003                        1 Query\\tDROP PREPARE stmt;   0      0  \n",
            "190553  3 Query\\tINSERT INTO time_zone_transition_type...   0      0  \n",
            "594782                             1 Query\\tEXECUTE stmt;   0      0  \n",
            "640547  1 Query\\tINSERT INTO help_relation (help_topic...   0      0  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the CSV file\n",
        "df = pd.read_csv(\"/content/drive/MyDrive/Dynamic_Analysis/mysql_dynamic_analysis/dynamic_analysis_dataset2.csv\")\n",
        "\n",
        "# Display 5 random rows\n",
        "print(df.sample(5))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RVtyeagvt6U4",
        "outputId": "85d9c808-59f5-4302-c537-a46c6e6f54eb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                          timestamp        source container_type log_type  \\\n",
            "240487  2025-03-07T18:55:18.092065Z  vulvariant33     vulnerable  general   \n",
            "13753   2025-03-07T18:16:19.307868Z   vulvariant6     vulnerable  general   \n",
            "12035   2025-03-07T18:16:14.058928Z   vulvariant6     vulnerable  general   \n",
            "338593  2025-03-07T17:51:54.723061Z   vulvariant3     vulnerable  general   \n",
            "410238  2025-03-07T18:33:35.540636Z  vulvariant21     vulnerable  general   \n",
            "\n",
            "                                              log_message cwe  label  \n",
            "240487  1 Query\\tINSERT INTO help_topic (help_topic_id...   0      0  \n",
            "13753   1 Query\\tINSERT INTO help_topic (help_topic_id...   0      0  \n",
            "12035                         1 Query\\tDROP PREPARE stmt;   0      0  \n",
            "338593       3 Query\\tSET @time_zone_id= LAST_INSERT_ID()   0      0  \n",
            "410238  3 Query\\tINSERT INTO time_zone (Use_leap_secon...   0      0  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import re\n",
        "import pandas as pd\n",
        "from datetime import datetime\n",
        "\n",
        "# mapping for CWE detection\n",
        "cwe_mapping = {\n",
        "    r\"DROP DATABASE\": \"CWE-287\",\n",
        "    r\"GRANT ALL PRIVILEGES\": \"CWE-264\",\n",
        "    r\"SELECT .*SLEEP\": \"CWE-400\",\n",
        "    r\"non_existing_table' OR '1'='1\": \"CWE-89\",\n",
        "    r\"TIMESTAMP with implicit DEFAULT value is deprecated\": \"CWE-489\",\n",
        "    r\"A deprecated TLS version TLSv1\": \"CWE-326\",\n",
        "    r\"A deprecated TLS version TLSv1\\.1\": \"CWE-326\",\n",
        "    r\"CA certificate .* is self signed\": \"CWE-295\",\n",
        "    r\"created with an empty password\": \"CWE-798\",\n",
        "    r\"'NO_AUTO_CREATE_USER' sql mode was not set\": \"CWE-16\"\n",
        "}\n",
        "\n",
        "def extract_timestamp(line):\n",
        "    pattern = r'^(\\d{4}-\\d{2}-\\d{2}T\\d{2}:\\d{2}:\\d{2}\\.\\d+Z)'\n",
        "    match = re.match(pattern, line)\n",
        "    if match:\n",
        "        return match.group(1)\n",
        "    return \"\"\n",
        "\n",
        "def determine_log_type(file_name):\n",
        "    lower_name = file_name.lower()\n",
        "    if \"error\" in lower_name:\n",
        "        return \"error\"\n",
        "    elif \"general\" in lower_name:\n",
        "        return \"general\"\n",
        "    else:\n",
        "        return \"unknown\"\n",
        "\n",
        "def detect_cwe(log_message):\n",
        "    for pattern, cwe in cwe_mapping.items():\n",
        "        if re.search(pattern, log_message, re.IGNORECASE):\n",
        "            return cwe\n",
        "    return \"\"\n",
        "\n",
        "def parse_log_file(file_path, source_folder):\n",
        "    entries = []\n",
        "    log_type = determine_log_type(os.path.basename(file_path))\n",
        "    container_type = \"vulnerable\" if \"vulvariant\" in source_folder.lower() else \"nonvulnerable\"\n",
        "\n",
        "    current_entry = None\n",
        "    try:\n",
        "        with open(file_path, 'r', encoding='utf-8', errors='ignore') as f:\n",
        "            for line in f:\n",
        "                line = line.rstrip(\"\\n\")\n",
        "                if not line:\n",
        "                    continue\n",
        "                ts = extract_timestamp(line)\n",
        "                if ts:\n",
        "                    if current_entry is not None:\n",
        "                        entries.append(current_entry)\n",
        "                    remainder = line[len(ts):].strip()\n",
        "                    current_entry = {\n",
        "                        \"timestamp\": ts,\n",
        "                        \"source\": source_folder,\n",
        "                        \"container_type\": container_type,\n",
        "                        \"log_type\": log_type,\n",
        "                        \"log_message\": remainder,\n",
        "                        \"cwe\": \"\",\n",
        "                        \"label\": None\n",
        "                    }\n",
        "                else:\n",
        "                    if current_entry is not None:\n",
        "                        current_entry[\"log_message\"] += \" \" + line.strip()\n",
        "            if current_entry is not None:\n",
        "                entries.append(current_entry)\n",
        "    except Exception as e:\n",
        "        print(f\"Error reading {file_path}: {e}\")\n",
        "\n",
        "    for entry in entries:\n",
        "        cwe_detected = detect_cwe(entry[\"log_message\"])\n",
        "        entry[\"cwe\"] = cwe_detected if cwe_detected else \"0\"\n",
        "        if container_type == \"vulnerable\":\n",
        "            entry[\"label\"] = 1 if cwe_detected else 0\n",
        "        else:\n",
        "            entry[\"label\"] = 0\n",
        "    return entries\n",
        "\n",
        "def build_dataset(logs_root):\n",
        "    all_entries = []\n",
        "    for variant in os.listdir(logs_root):\n",
        "        variant_path = os.path.join(logs_root, variant)\n",
        "        if os.path.isdir(variant_path):\n",
        "            for file in os.listdir(variant_path):\n",
        "                file_path = os.path.join(variant_path, file)\n",
        "                entries = parse_log_file(file_path, variant)\n",
        "                all_entries.extend(entries)\n",
        "    return pd.DataFrame(all_entries)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # Set the logs directory\n",
        "    logs_directory = \"/content/drive/MyDrive/Dynamic_Analysis/mysql_dynamic_analysis/mysql_logs\"\n",
        "\n",
        "    # Build the dataset\n",
        "    df_dataset = build_dataset(logs_directory)\n",
        "\n",
        "    # Print 5 random rows for verification\n",
        "    print(\"Random 5 rows from dataset:\")\n",
        "    print(df_dataset.sample(5))\n",
        "\n",
        "    # Save the dataset to CSV\n",
        "    output_csv = \"/content/drive/MyDrive/Dynamic_Analysis/mysql_dynamic_analysis/dynamic_analysis_dataset3.csv\"\n",
        "    df_dataset.to_csv(output_csv, index=False)\n",
        "\n",
        "    print(f\"Dataset created with {len(df_dataset)} entries and saved to {output_csv}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8DpvTJFYu-Oj",
        "outputId": "f87658cd-2e46-43ca-e039-d6df6b477db5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random 5 rows from dataset:\n",
            "                          timestamp           source container_type log_type  \\\n",
            "421174  2025-03-07T18:33:13.974277Z     vulvariant20     vulnerable  general   \n",
            "814140  2025-03-07T18:39:32.748462Z  nonvulvariant33     vulnerable  general   \n",
            "694153  2025-03-07T18:32:11.880499Z  nonvulvariant22     vulnerable  general   \n",
            "554602  2025-03-07T18:16:49.268143Z   nonvulvariant7     vulnerable  general   \n",
            "864879  2025-03-07T18:27:37.251176Z  nonvulvariant11     vulnerable  general   \n",
            "\n",
            "                                              log_message cwe  label  \n",
            "421174  3 Query\\tINSERT INTO time_zone_transition (Tim...   0      0  \n",
            "814140  1 Query\\tINSERT INTO help_keyword (help_keywor...   0      0  \n",
            "694153                        1 Query\\tDROP PREPARE stmt;   0      0  \n",
            "554602  3 Query\\tINSERT INTO time_zone (Use_leap_secon...   0      0  \n",
            "864879  1 Query\\tINSERT INTO help_relation (help_topic...   0      0  \n",
            "Dataset created with 911888 entries and saved to /content/drive/MyDrive/Dynamic_Analysis/mysql_dynamic_analysis/dynamic_analysis_dataset3.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load your CSV dataset\n",
        "df = pd.read_csv(\"/content/drive/MyDrive/Dynamic_Analysis/mysql_dynamic_analysis/dynamic_analysis_dataset3.csv\")\n",
        "\n",
        "# Count occurrences of each label\n",
        "label_counts = df['label'].value_counts()\n",
        "\n",
        "print(\"Label Counts:\")\n",
        "print(label_counts)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ApS3LmLTvxWZ",
        "outputId": "2fe440d0-71ac-445c-9b49-5d305e24f6b4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Label Counts:\n",
            "label\n",
            "0    909590\n",
            "1      2298\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**without proper mapping just put 1 for all non vulnerable config which is not correct**"
      ],
      "metadata": {
        "id": "JI_Cg407rQ0y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import re\n",
        "import pandas as pd\n",
        "from datetime import datetime\n",
        "\n",
        "# mapping for CWE detection\n",
        "cwe_mapping = {\n",
        "    r\"DROP DATABASE\": \"CWE-287\",\n",
        "    r\"GRANT ALL PRIVILEGES\": \"CWE-264\",\n",
        "    r\"SELECT .*SLEEP\": \"CWE-400\",\n",
        "    r\"non_existing_table' OR '1'='1\": \"CWE-89\",\n",
        "    r\"TIMESTAMP with implicit DEFAULT value is deprecated\": \"CWE-489\",\n",
        "    r\"A deprecated TLS version TLSv1\": \"CWE-326\",\n",
        "    r\"A deprecated TLS version TLSv1\\.1\": \"CWE-326\",\n",
        "    r\"CA certificate .* is self signed\": \"CWE-295\",\n",
        "    r\"created with an empty password\": \"CWE-798\",\n",
        "    r\"'NO_AUTO_CREATE_USER' sql mode was not set\": \"CWE-16\"\n",
        "}\n",
        "\n",
        "def extract_timestamp(line):\n",
        "    pattern = r'^(\\d{4}-\\d{2}-\\d{2}T\\d{2}:\\d{2}:\\d{2}\\.\\d+Z)'\n",
        "    match = re.match(pattern, line)\n",
        "    if match:\n",
        "        return match.group(1)\n",
        "    return \"\"\n",
        "\n",
        "def determine_log_type(file_name):\n",
        "    lower_name = file_name.lower()\n",
        "    if \"error\" in lower_name:\n",
        "        return \"error\"\n",
        "    elif \"general\" in lower_name:\n",
        "        return \"general\"\n",
        "    else:\n",
        "        return \"unknown\"\n",
        "\n",
        "def detect_cwe(log_message):\n",
        "    for pattern, cwe in cwe_mapping.items():\n",
        "        if re.search(pattern, log_message, re.IGNORECASE):\n",
        "            return cwe\n",
        "    return \"\"\n",
        "\n",
        "def determine_container_type(source_folder):\n",
        "    s = source_folder.lower()\n",
        "    if s.startswith(\"nonvulvariant\"):\n",
        "        return \"nonvulnerable\"\n",
        "    elif s.startswith(\"vulvariant\"):\n",
        "        return \"vulnerable\"\n",
        "    else:\n",
        "        return \"unknown\"\n",
        "\n",
        "def parse_log_file(file_path, source_folder):\n",
        "    entries = []\n",
        "    log_type = determine_log_type(os.path.basename(file_path))\n",
        "    container_type = determine_container_type(source_folder)\n",
        "\n",
        "    current_entry = None\n",
        "    try:\n",
        "        with open(file_path, 'r', encoding='utf-8', errors='ignore') as f:\n",
        "            for line in f:\n",
        "                line = line.rstrip(\"\\n\")\n",
        "                if not line:\n",
        "                    continue\n",
        "                ts = extract_timestamp(line)\n",
        "                if ts:\n",
        "                    if current_entry is not None:\n",
        "                        entries.append(current_entry)\n",
        "                    remainder = line[len(ts):].strip()\n",
        "                    current_entry = {\n",
        "                        \"timestamp\": ts,\n",
        "                        \"source\": source_folder,\n",
        "                        \"container_type\": container_type,\n",
        "                        \"log_type\": log_type,\n",
        "                        \"log_message\": remainder,\n",
        "                        \"cwe\": \"\",\n",
        "                        \"label\": None\n",
        "                    }\n",
        "                else:\n",
        "                    if current_entry is not None:\n",
        "                        current_entry[\"log_message\"] += \" \" + line.strip()\n",
        "            if current_entry is not None:\n",
        "                entries.append(current_entry)\n",
        "    except Exception as e:\n",
        "        print(f\"Error reading {file_path}: {e}\")\n",
        "\n",
        "    # Determine CWE and set label for each entry.\n",
        "    for entry in entries:\n",
        "        cwe_detected = detect_cwe(entry[\"log_message\"])\n",
        "        entry[\"cwe\"] = cwe_detected if cwe_detected else \"0\"\n",
        "        if container_type == \"vulnerable\":\n",
        "            entry[\"label\"] = 1\n",
        "        else:\n",
        "            entry[\"label\"] = 0\n",
        "    return entries\n",
        "\n",
        "def build_dataset(logs_root):\n",
        "    all_entries = []\n",
        "    for variant in os.listdir(logs_root):\n",
        "        variant_path = os.path.join(logs_root, variant)\n",
        "        if os.path.isdir(variant_path):\n",
        "            for file in os.listdir(variant_path):\n",
        "                file_path = os.path.join(variant_path, file)\n",
        "                entries = parse_log_file(file_path, variant)\n",
        "                all_entries.extend(entries)\n",
        "    return pd.DataFrame(all_entries)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # Set the logs directory (update to your actual Drive path)\n",
        "    logs_directory = \"/content/drive/MyDrive/Dynamic_Analysis/mysql_dynamic_analysis/mysql_logs\"\n",
        "\n",
        "    # Build the dataset from the log files\n",
        "    df_dataset = build_dataset(logs_directory)\n",
        "\n",
        "    # Print 5 random rows for verification\n",
        "    print(\"Random 5 rows from dataset:\")\n",
        "    print(df_dataset.sample(5))\n",
        "\n",
        "    # Count the number of vulnerable (label=1) and non-vulnerable (label=0) entries\n",
        "    label_counts = df_dataset['label'].value_counts()\n",
        "    print(\"\\nLabel counts:\")\n",
        "    print(label_counts)\n",
        "\n",
        "    # Save the dataset to a CSV file\n",
        "    output_csv = \"/content/drive/MyDrive/Dynamic_Analysis/mysql_dynamic_analysis/ffdynamic_analysis_dataset.csv\"\n",
        "    df_dataset.to_csv(output_csv, index=False)\n",
        "\n",
        "    print(f\"\\nDataset created with {len(df_dataset)} entries and saved to {output_csv}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dKUxOYyw3cVK",
        "outputId": "154cf21a-038e-49d0-88f3-af07344bce19"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random 5 rows from dataset:\n",
            "                          timestamp           source container_type log_type  \\\n",
            "657145  2025-03-07T17:51:04.657507Z   nonvulvariant4  nonvulnerable  general   \n",
            "88410   2025-03-07T17:52:09.098174Z      vulvariant5     vulnerable  general   \n",
            "716154  2025-03-07T18:33:31.923557Z  nonvulvariant25  nonvulnerable  general   \n",
            "18015   2025-03-07T18:16:43.052599Z      vulvariant6     vulnerable  general   \n",
            "610912  2025-03-07T18:59:31.607723Z  nonvulvariant45  nonvulnerable  general   \n",
            "\n",
            "                                              log_message cwe  label  \n",
            "657145  1 Query\\tINSERT INTO help_relation (help_topic...   0      0  \n",
            "88410   3 Query\\tINSERT INTO time_zone_transition_type...   0      1  \n",
            "716154  3 Query\\tINSERT INTO time_zone_name (Name, Tim...   0      0  \n",
            "18015   3 Query\\tINSERT INTO time_zone (Use_leap_secon...   0      1  \n",
            "610912                        1 Query\\tDROP PREPARE stmt;   0      0  \n",
            "\n",
            "Label counts:\n",
            "label\n",
            "1    527457\n",
            "0    384431\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Dataset created with 911888 entries and saved to /content/drive/MyDrive/Dynamic_Analysis/mysql_dynamic_analysis/ffdynamic_analysis_dataset.csv\n"
          ]
        }
      ]
    }
  ]
}